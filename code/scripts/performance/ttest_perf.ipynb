{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1c94fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistical comparison between Llama2 7B Chat and Llama2 7B Chat Uncensored:\n",
      "\tBenchmark: ARC\n",
      "\t\tLow variability detected, skipping test.\n",
      "\tBenchmark: TruthfulQA\n",
      "\t\tLow variability detected, skipping test.\n",
      "\tBenchmark: HellaSwag\n",
      "\t\tLow variability detected, skipping test.\n",
      "\tBenchmark: MMLU\n",
      "\t\tLow variability detected, skipping test.\n",
      "\tBenchmark: MNLI\n",
      "\t\tLow variability detected, skipping test.\n",
      "\n",
      "Statistical comparison between Llama2 7B Chat and Llama2 13B Chat:\n",
      "\tBenchmark: ARC\n",
      "\t\tLow variability detected, skipping test.\n",
      "\tBenchmark: TruthfulQA\n",
      "\t\tLow variability detected, skipping test.\n",
      "\tBenchmark: HellaSwag\n",
      "\t\tLow variability detected, skipping test.\n",
      "\tBenchmark: MMLU\n",
      "\t\tLow variability detected, skipping test.\n",
      "\tBenchmark: MNLI\n",
      "\t\tLow variability detected, skipping test.\n",
      "\n",
      "Statistical comparison between Llama2 7B Chat and Llama2 13B Chat Uncensored:\n",
      "\tBenchmark: ARC\n",
      "\t\tLow variability detected, skipping test.\n",
      "\tBenchmark: TruthfulQA\n",
      "\t\tLow variability detected, skipping test.\n",
      "\tBenchmark: HellaSwag\n",
      "\t\tLow variability detected, skipping test.\n",
      "\tBenchmark: MMLU\n",
      "\t\tLow variability detected, skipping test.\n",
      "\tBenchmark: MNLI\n",
      "\t\tLow variability detected, skipping test.\n",
      "\n",
      "Statistical comparison between Llama2 7B Chat Uncensored and Llama2 13B Chat Uncensored:\n",
      "\tBenchmark: ARC\n",
      "\t\tLow variability detected, skipping test.\n",
      "\tBenchmark: TruthfulQA\n",
      "\t\tLow variability detected, skipping test.\n",
      "\tBenchmark: HellaSwag\n",
      "\t\tLow variability detected, skipping test.\n",
      "\tBenchmark: MMLU\n",
      "\t\tLow variability detected, skipping test.\n",
      "\tBenchmark: MNLI\n",
      "\t\tLow variability detected, skipping test.\n",
      "\n",
      "Statistical comparison between Llama2 13B Chat and Llama2 13B Chat Uncensored:\n",
      "\tBenchmark: ARC\n",
      "\t\tLow variability detected, skipping test.\n",
      "\tBenchmark: TruthfulQA\n",
      "\t\tLow variability detected, skipping test.\n",
      "\tBenchmark: HellaSwag\n",
      "\t\tLow variability detected, skipping test.\n",
      "\tBenchmark: MMLU\n",
      "\t\tLow variability detected, skipping test.\n",
      "\tBenchmark: MNLI\n",
      "\t\tLow variability detected, skipping test.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "# Accuracy data for the models\n",
    "accuracy_data = {\n",
    "    'Llama2 7B Chat': {\n",
    "        'ARC': 0.527,\n",
    "        'TruthfulQA': 0.453,\n",
    "        'HellaSwag': 0.785,\n",
    "        'MMLU': 0.470,\n",
    "        'MNLI': 0.495\n",
    "    },\n",
    "    'Llama2 7B Chat Uncensored': {\n",
    "        'ARC': 0.532,\n",
    "        'TruthfulQA': 0.427,\n",
    "        'HellaSwag': 0.786,\n",
    "        'MMLU': 0.353,\n",
    "        'MNLI': 0.447\n",
    "    },\n",
    "    'Llama2 13B Chat': {\n",
    "        'ARC': 0.592,\n",
    "        'TruthfulQA': 0.439,\n",
    "        'HellaSwag': 0.819,\n",
    "        'MMLU': 0.461,\n",
    "        'MNLI': 0.474\n",
    "    },\n",
    "    'Llama2 13B Chat Uncensored': {\n",
    "        'ARC': 0.600,\n",
    "        'TruthfulQA': 0.408,\n",
    "        'HellaSwag': 0.824,\n",
    "        'MMLU': 0.530,\n",
    "        'MNLI': 0.459\n",
    "    }\n",
    "}\n",
    "\n",
    "# Define significance level\n",
    "alpha = 0.05\n",
    "\n",
    "# Perform t-test for each benchmark\n",
    "benchmarks = ['ARC', 'TruthfulQA', 'HellaSwag', 'MMLU', 'MNLI']\n",
    "model_combinations = [('Llama2 7B Chat', 'Llama2 7B Chat Uncensored'),\n",
    "                      ('Llama2 7B Chat', 'Llama2 13B Chat'),\n",
    "                      ('Llama2 7B Chat', 'Llama2 13B Chat Uncensored'),\n",
    "                      ('Llama2 7B Chat Uncensored', 'Llama2 13B Chat Uncensored'),\n",
    "                      ('Llama2 13B Chat', 'Llama2 13B Chat Uncensored')]\n",
    "\n",
    "for model1, model2 in model_combinations:\n",
    "    print(f\"Statistical comparison between {model1} and {model2}:\")\n",
    "    for benchmark in benchmarks:\n",
    "        print(f\"\\tBenchmark: {benchmark}\")\n",
    "        data1 = accuracy_data[model1][benchmark]\n",
    "        data2 = accuracy_data[model2][benchmark]\n",
    "        \n",
    "        if np.var(data1) < 1e-9 or np.var(data2) < 1e-9:\n",
    "            print(\"\\t\\tLow variability detected, skipping test.\")\n",
    "            continue\n",
    "        \n",
    "        t_statistic, p_value = ttest_ind(data1, data2)\n",
    "        print(\"\\t\\tp-value:\", p_value)\n",
    "        if p_value < alpha:\n",
    "            print(\"\\t\\tSignificant difference exists.\")\n",
    "        else:\n",
    "            print(\"\\t\\tNo significant difference.\")\n",
    "    print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cba87b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
